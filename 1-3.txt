# 돌아가지는 않는데 원인을 모르겠다

import numpy as np
import matplotlib.pyplot as plt

class Player(object):
    def __init__(self, currentSum, usableAce, dealersCard):
        self.currentSum = currentSum
        self.dealersCard = dealersCard
        self.usableAce = usableAce
        self.usingAce = self.usableAce
        
    def ReceiveCard(self, card):
        if self.usingAce and self.currnetSum + card > 21:
            self.usingAce = False
            self.currentSum += card - 10
        else:
            self.currentSum += card
            
    def GetState(self):
        return (self.currentSum, self.usableAce, self.dealersCard)
    
    def GetValue(self):
        return self.currentSum
    
    def ShouldHit(self, policy):
        return policy[self.GetState()]
    
    def Bust(self):
        return self.GetValue() > 21
    
    
class Dealer(object):
    def __init__(self, cards):
        self.cards = cards
        
    def ReceiveCard(self, card):
        self.cards.append(card)
        
    def GetValue(self):
        currentSum = 0
        aceCount = 0
        for card in self.cards:
            if card == 1:
                aceCount += 1
            else:
                currentSum += card             
        while aceCount > 0:
            aceCount -= 1
            currentSum += 11
            if currentSum > 21:
                aceCount += 1
                currentSum -= 11
                currentSum += aceCount
                break    
        return currentSum
    
    def SouldHit(self):
        if self.GetValue() >= 17:
            return False
        else:
            return True
        
    def Bust(self):
        return self.GetValue() > 21
    

class StateActionInfo(object):
    def __init__(self):
        self.stateActionPairs = []
        self.stateActionMap = set()
    
    def AddPair(self, pair):
        if pair in self.stateActionMap:
            return
        
        self.stateActionPairs.append(pair)
        self.stateActionMap.add(pair)
        
def EvaluateAndImprovePolicy(qMap, policy, returns, stateActionPairs, reward):
    for pair in stateActionPairs:
        returns[pair] += 1
        qMap[pair] = qMap[pair] + ((reward - qMap[pair]) / returns[pair])
        
        state = pair[0]
        sholudHit = False
        
        if qMap[(state, True)] > qMap[(state, False)]:
            shouldHit = True
            
        policy[state] = shouldHit
        
def newCard():
    card = np.random.randint(1, 14)
    
    if card > 9:
        return 10
    else:
        return card
    
def GenerateStart(qMap, policy, returns):
    platerSum = np.random.randint(11, 22)
    usableAce = bool(np.random.randint(0, 2))
    
    player = Player(playerSum, usableAce, np.random.randint(1, 11))
    dealer = Dealer([np.random.randint(1, 11)])
    
    stateActionInfo = StateActionInfo()
    hitAction = bool(np.random.randint(0, 2))
    stateActionInfo.AddPair((player.GetState(), hitAction))
    
    if hitAction:
        player.ReceiveCard(newCard())
        
        while not player.Bust() and player.ShouldHit(policy):
            stateActionInfo.AddPair((player.GetState(), True))
            player.ReceiveCard(newCard())
            
    if player.Bust():
        EvaluateAndImprovePolicy(qMap, policy, returns, stateActionInfo.stateActionPairs, -1)
        return
    
    stateActionInfo.AddPair((player.GetState(), False))
    dealer.ReceiveCard(newCard())
    
    while not dealer.Bust() and dealer.shouldHit():
        dealer.cards.append(newCard())
        
    if dealer.Bust() or dealer.GetValue() < player.GetValue():
        EvaluateAndImprovePolicy(qMap, policy, returns, stateActionInfo.stateActionPairs, 1)
    elif dealer.GetValue() > player.GetValue():
        EvaluateAndImprovePolicy(qMap, policy, returns, stateActionInfo.stateActionPairs, -1)
    else:
        EvaluateAndImprovePolicy(qMap, policy, returns, stateActionInfo.stateActionPairs, 0)
        
qMap = {}
policy = {}
returns = {}

for playerSum in range(11, 22):
    for usableAce in range(2):
        for dealersCard in range(1, 11):
            playerState = (playerSum, bool(usableAce), dealersCard)
            qMap[(playerState, False)] = 0
            qMap[(playerState, True)] = 0
            returns[(playerState, False)] = 0
            returns[(playerState, True)] = 0
            
            if playerSum == 20 or playerSum == 21:
                policy[playerState] = False
            else:
                policy[playerState] = True
                
for i in range(1000000):
    GenerateStart(qMap, policy, returns)
    
x11 = []
y11 = []
x12 = []
y12 = []
x21 = []
y21 = []
x22 = []
y22 = []

for playerState in policy:
    if playerState[1]:
        if policy[playerState]:
            x11.append(playerState[2] - 1)
            y11.append(playerState[0] - 11)
        else:
            x12.append(playerState[2] - 1)
            y12.append(playerState[0] - 11)
    else:
        if policy[playerState]:
            x21.append(playerState[2] - 1)
            y21.append(playerState[0] - 11)
        else:
            x22.append(playerState[2] - 1)
            y22.append(playerState[0] - 11)
            
plt.figure(0)
plt.title('With Usable Ace')
plt.scatter(x11, y11, color='blue')
plt.scatter(x12, y12, color='yellow')
plt.xticks(range(10), ['A', '2', '3', '4', '5', '6', '7', '8', '9', '10'])
plt.yticks(range(11), ['11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])
            
plt.figure(1)
plt.title('Without Usable Ace')
plt.scatter(x21, y21, color='blue')
plt.scatter(x22, y22, color='yellow')
plt.xticks(range(10), ['A', '2', '3', '4', '5', '6', '7', '8', '9', '10'])
plt.yticks(range(11), ['11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])

plt.show()






######################################
import numpy as np

BOARD_ROWS = 3
BOARD_COLS = 4
WIN_STATE = (0, 3)    #보상값이 +1인 종단 상태 위치
LOSE_STATE = (1, 3)    #보상값이 -1인 종단 상태 위치
BLOCKED_STATE = (1, 1)    #이동할 수 없는 영역
START = (2, 0)    #시작 상태 위치
DETERMINISTIC = False    #상태 전이 함수의 확률 적용 플래그(False일 경우 적용)

class State:
    def __init__(self, state = START):
        self.state = state
        self.isEnd = False
        self.determine = DETERMINISTIC
        
    def giveReward(self):
        if self.state == WIN_STATE:
            return 1
        elif self.state == LOSE_STATE:
            return -1
        else:
            return 0
        
    def isEndFunc(self):
        if (self.state == WIN_STATE) or (self.state == LOSE_STATE):
            self.isEnd = True
            
    def _chooseActionProb(self, action):
        if action == 'U':
            return np.random.choice(['U','L','R'], p = [0.8, 0.1, 0.1])
        if action == 'D':
            return np.random.choice(['D','L','R'], p = [0.8, 0.1, 0.1])
        if action == 'L':
            return np.random.choice(['L','U','D'], p = [0.8, 0.1, 0.1])
        if action == 'R':
            return np.random.choice(['R','U','D'], p = [0.8, 0.1, 0.1])
        
    #격자 공간에서 다음 상태를 반환
    def nxtPosition(self, action):
        if self.determine:
            if action == "U":
                nxtState = (self.state[0] - 1, self.state[1])
            elif action == "D":
                nxtState = (self.state[0] + 1, self.state[1])
            elif action == "L":
                nxtState = (self.state[0], self.state[1] - 1)
            else:
                nxtState = (self.state[0], self.state[1] + 1)
            self.determine = False
        else:
            #상태 전이 함수를 적용
            action = self._chooseActionProb(action)
            self.determine = True
            nxtState = self.nxtPosition(action)
            
        #벽을 뚫거나 이동할 수 없는 영역으로 상태를 바꿀 수 없음
        if 0 <= nxtState[0] <= 2:
            if 0 <= nxtState[1] <= 3:
                if nxtState != BLOCKED_STATE:
                    return nxtState
        return self.state
    
class Agent:
    def __init__(self):
        self.states = []    #위치와 행동을 기록
        self.actions = ['U', 'D', 'L', 'R']
        self.State = State()
        self.isEnd = self.State.isEnd
        self.lr = 0.2
        self.decay_gamma = 0.9    #할인율 0.9로 설정
        
        #전체 상태에 대해 Q함수(행동 가치 함수)의 값 초기화
        self.Q_values = {}
        for i in range(BOARD_ROWS):
            for j in range(BOARD_COLS):
                self.Q_values[(i, j)] = {}
                for a in self.actions:
                    self.Q_values[(i, j)][a] = 0
                    
    #Q값을 가장 극대화 하는 방향으로 다음 행동 선택
    def chooseAction(self):
        max_nxt_reward = 0
        action =""
        
        for a in self.actions:
            current_position = self.State.state
            nxt_reward = self.Q_values[current_position][a]
            if nxt_reward >= max_nxt_reward:
                action = a
                max_nxt_reward = nxt_reward
            #print("current pos : {}, greedy action : {}".format(self.State.state, action))
        return action
    
    #행동 후 상태 업데이트
    def takeAction(self, action):
        position = self.State.nxtPosition(action)
        return State(state = position)
    
    #종단 상태 도달 후 에피소드 초기화
    def reset(self):
        self.states = []
        self.State = State()
        self.isEnd = self.State.isEnd
        
    #에피소드 개수만큼 반복
    def play(self, episodes = 10):
        i = 0
        while i < episodes:
            #게임이 끝날 때 까지 보상값의 역전파 진행
            if self.State.isEnd:
                #역전파
                reward = self.State.giveReward()
                for a in self.actions:
                    self.Q_values[self.State.state][a] = reward
                #print("Game End Reward", reward)
                for s in reversed(self.states):
                    current_q_value = self.Q_values[s[0]][s[1]]
                    reward = current_q_value + self.lr * (self.decay_gamma * reward - current_q_value)
                    self.Q_values[s[0]][s[1]] = round(reward, 3)
                self.reset()
                i += 1
            else:
                action = self.chooseAction()
                #추적 추가
                self.states.append([(self.State.state), action])
                #print("current position {} action {}".format(self.State.state, action))
                #액션을 취하면, 다음 상태에 도달
                self.State = self.takeAction(action)
                #종료 상태로 표기
                self.State.isEndFunc()
                #print("nxt state", self.State.state)
                #print("---------------------------")
                self.isEnd = self.State.isEnd
                
ag = Agent()

ag.play(1000)
print('latest Q-values ... \n')
print(ag.Q_values)